# Backend Environment Variables
# Copy this file to .env for local development

# Server Configuration
PORT=3001

# Ollama Configuration
# Base URL for Ollama API (default: http://localhost:11434)
OLLAMA_BASE_URL=http://localhost:11434

# Model to use for chat (default: llama3.2:1b)
# Examples: llama3.2:1b, llama3.2:3b, mistral, codellama
OLLAMA_MODEL=llama3.2:1b

# Embedding model for RAG vector generation
# Examples: nomic-embed-text, mxbai-embed-large, all-minilm, snowflake-arctic-embed
EMBEDDING_MODEL=nomic-embed-text

# System Prompts
SYSTEM_PROMPT=
RAG_SYSTEM_PROMPT=

# PostgreSQL Database
DATABASE_HOST=localhost
DATABASE_PORT=5432
DATABASE_USER=postgres
DATABASE_PASSWORD=postgres
DATABASE_NAME=ai_agent

# Qdrant Vector Database
QDRANT_URL=http://localhost:6333

# Collection name for storing document vectors
QDRANT_COLLECTION=documents

# Cors Configuration
CORS_ORIGINS=http://localhost:3000
